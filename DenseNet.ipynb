{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import DenseModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#import, load and normalize CIFAR\n",
    "\n",
    "trainBatchSize = 128\n",
    "testBatchSize = 128\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainBatchSize,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=testBatchSize,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "          'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants and net definition\n",
    "learning_rate = 0.002\n",
    "numEpochs = 300\n",
    "lr_decay = 0.995\n",
    "net = DenseModule.DenseLinearlyInvariantNet(32, 4, 10, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPerformance(dataLoader, dataName):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    testCriterion = nn.CrossEntropyLoss(size_average=False)\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data in dataLoader:\n",
    "            inputs, labels = data\n",
    "            if cuda_avail:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "            outputs = net(inputs)\n",
    "            loss += testCriterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Loss and accuracy on the %s set: %.5f, %.2f %%' % (dataName, loss / total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Linearly Invariant Net will be trained!\n",
      "Number of parameters:  43674\n",
      "Number of epochs:  300\n",
      "[1] loss: 2.165 LR: 0.00199 Epoch time: 6.32 s, Remaining time: 1890.91 s\n",
      "[2] loss: 1.937 LR: 0.00198 Epoch time: 6.33 s, Remaining time: 1886.08 s\n",
      "[3] loss: 1.776 LR: 0.00197 Epoch time: 6.35 s, Remaining time: 1885.89 s\n",
      "[4] loss: 1.682 LR: 0.00196 Epoch time: 6.40 s, Remaining time: 1894.09 s\n",
      "[5] loss: 1.606 LR: 0.00195 Epoch time: 6.39 s, Remaining time: 1886.28 s\n",
      "[6] loss: 1.552 LR: 0.00194 Epoch time: 6.41 s, Remaining time: 1884.74 s\n",
      "[7] loss: 1.503 LR: 0.00193 Epoch time: 6.44 s, Remaining time: 1887.78 s\n",
      "[8] loss: 1.467 LR: 0.00192 Epoch time: 6.39 s, Remaining time: 1867.32 s\n",
      "[9] loss: 1.425 LR: 0.00191 Epoch time: 6.41 s, Remaining time: 1865.99 s\n",
      "[10] loss: 1.390 LR: 0.00190 Epoch time: 6.45 s, Remaining time: 1869.88 s\n",
      "Loss and accuracy on the train set: 1.35074, 53.43 %\n",
      "Loss and accuracy on the test set: 1.45726, 49.84 %\n",
      "[11] loss: 1.359 LR: 0.00189 Epoch time: 6.41 s, Remaining time: 1852.01 s\n",
      "[12] loss: 1.332 LR: 0.00188 Epoch time: 6.43 s, Remaining time: 1852.76 s\n",
      "[13] loss: 1.315 LR: 0.00187 Epoch time: 6.46 s, Remaining time: 1854.92 s\n",
      "[14] loss: 1.298 LR: 0.00186 Epoch time: 6.43 s, Remaining time: 1839.31 s\n",
      "[15] loss: 1.281 LR: 0.00186 Epoch time: 6.46 s, Remaining time: 1841.89 s\n",
      "[16] loss: 1.264 LR: 0.00185 Epoch time: 6.43 s, Remaining time: 1825.41 s\n",
      "[17] loss: 1.246 LR: 0.00184 Epoch time: 6.45 s, Remaining time: 1824.74 s\n",
      "[18] loss: 1.233 LR: 0.00183 Epoch time: 6.46 s, Remaining time: 1821.69 s\n",
      "[19] loss: 1.224 LR: 0.00182 Epoch time: 6.60 s, Remaining time: 1853.65 s\n",
      "[20] loss: 1.209 LR: 0.00181 Epoch time: 6.61 s, Remaining time: 1851.28 s\n",
      "Loss and accuracy on the train set: 1.17670, 59.68 %\n",
      "Loss and accuracy on the test set: 1.38538, 52.98 %\n",
      "[21] loss: 1.205 LR: 0.00180 Epoch time: 6.53 s, Remaining time: 1823.15 s\n"
     ]
    }
   ],
   "source": [
    "#Train on training set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "def adjust_learning_rate():\n",
    "    global learning_rate\n",
    "    learning_rate *= lr_decay\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = learning_rate\n",
    "\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "if cuda_avail:\n",
    "    net.cuda()\n",
    "\n",
    "net.printNet()\n",
    "print(\"Number of epochs: \", numEpochs)\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "    timeStart = time.time()\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    numBatches = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        if cuda_avail:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        numBatches += 1\n",
    "    timeElapsed = time.time() - timeStart\n",
    "    adjust_learning_rate()\n",
    "        \n",
    "    print('[%d] loss: %.3f LR: %.5f Epoch time: %.2f s, Remaining time: %.2f s' %\n",
    "          (epoch + 1, running_loss / numBatches, learning_rate, timeElapsed, (numEpochs - epoch - 1) * timeElapsed))\n",
    "    \n",
    "    if ((epoch + 1) % 10 == 0):\n",
    "        testPerformance(trainloader, \"train\")\n",
    "        testPerformance(testloader, \"test\")\n",
    "\n",
    "print('Finished Training')\n",
    "testPerformance(trainloader, \"train\")\n",
    "testPerformance(testloader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distribution over classes in test set\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        if cuda_avail:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %.2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
